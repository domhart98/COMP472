{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "project_skeleton.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/domhart98/COMP472_A1/blob/main/project_skeleton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlun5t_GO2Xi"
      },
      "source": [
        "# COMP425/6341 Computer Vision - Project skeleton\n",
        "\n",
        "## 0 Import KMNIST dataset (1 pts)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4G0UJ4EcIfX"
      },
      "source": [
        "# import required libraries, DO NOT MODIFY!\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets import ImageFolder,KMNIST\n",
        "from torch.utils.data import Dataset, random_split, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import make_grid\n",
        "from torch.optim import Adam\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ADRTRFNcIfY"
      },
      "source": [
        "### TODO: set random seed to your Student ID\n",
        "random_seed = 40068282\n",
        "torch.manual_seed(random_seed);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdFR_tBZKAiR"
      },
      "source": [
        "Run the cells below to initialize the train and test loaders for KMNIST and visualize one of its samples.\n",
        "\n",
        "**Experiments:** <br>\n",
        "1. Change `batch_size` based on the device you are using.<br>\n",
        "2. Try more complicated transformations on train set.<br>\n",
        "3. Visualize different samples from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9UQampoKAiS"
      },
      "source": [
        "# datasets hyper parameters\n",
        "batch_size = 20\n",
        "train_transform = transforms.Compose([transforms.ToTensor()])\n",
        "test_transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "# Initialize kmnist train and test datasets\n",
        "# These two lines will download the datasets in a folder called KMNIST.\n",
        "# The folder will be written in the same directory as this script.\n",
        "# The download will occur once. Subsequent executions will not re-download the datasets if they exist.\n",
        "kmnist_train_set = KMNIST(root='.',\n",
        "                         train=True,\n",
        "                         download=True,\n",
        "                         transform=train_transform)\n",
        "kmnist_test_set = KMNIST(root='.',\n",
        "                         train=False,\n",
        "                         download=True,\n",
        "                         transform=test_transform)\n",
        "\n",
        "# Initialize kmnist train and test data loaders. \n",
        "kmnist_train_loader = torch.utils.data.DataLoader(kmnist_train_set,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True,\n",
        "                                           drop_last=True)\n",
        "kmnist_test_loader = torch.utils.data.DataLoader(kmnist_test_set,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False,\n",
        "                                          drop_last=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NR2HHDGKAiS",
        "scrolled": true
      },
      "source": [
        "### TODO: visualize a sample image and corresponding label from KMNIST\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q78iW7WKAiT"
      },
      "source": [
        "## 1 Feed-forward Neural network\n",
        "In this section, you will implement a simple feed-forward network from scratch. Follow the instructions/comments in each subsection to complete the general structure of the network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJhzKiUyKAiT"
      },
      "source": [
        "### 1.1 Activation Functions (4 + 4 + 4 pts)\n",
        "Implement [Sigmoid](https://en.wikipedia.org/wiki/Sigmoid_function), [ReLU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)) and [Identity](https://en.wikipedia.org/wiki/Identity_function) functions. This functions will later be used in network architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiIHSa5fKAiU"
      },
      "source": [
        "def Sigmoid(x):\n",
        "    \"\"\" Identity activation function\n",
        "    Args:\n",
        "        x (torch.tensor)\n",
        "    Return:\n",
        "        torch.tensor: a tensor of shape of x\n",
        "    \"\"\"\n",
        "    ### TODO: Fill out this function\n",
        "    pass\n",
        "    \n",
        "\n",
        "def ReLU(x):\n",
        "    \"\"\" ReLU activation function\n",
        "    Args:\n",
        "        x (torch.tensor)\n",
        "    Return:\n",
        "        torch.tensor: a tensor of shape of x\n",
        "    \"\"\"\n",
        "    ### TODO: Fill out this function\n",
        "    pass\n",
        "\n",
        "def Identity(x):\n",
        "    \"\"\" Identity activation function\n",
        "    Args:\n",
        "        x (torch.tensor)\n",
        "    Return:\n",
        "        torch.tensor: a tensor of shape of x\n",
        "    \"\"\"\n",
        "    ### TODO: Fill out this function\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnLM6u8aKAiU"
      },
      "source": [
        "### 1.2 Cross Entropy Loss (7.5 + 7.5 pts)\n",
        "Implement the Softmax function and Cross Entropy loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mv24yWSyKAiU"
      },
      "source": [
        "def Softmax(x,dim):\n",
        "    \"\"\" Softmax function\n",
        "    Args:torch.log(\n",
        "        x (torch.tensor): inputs tensor of size (B,F)\n",
        "        dim (int): A dimension along which Softmax will be computed\n",
        "    Return:\n",
        "        torch.tensor: a tensor of shape of x\n",
        "    \"\"\"\n",
        "    ### TODO: Fill out this function\n",
        "    pass\n",
        "\n",
        "def CE_loss(predictions,labels):\n",
        "    \"\"\" Cross entropy loss\n",
        "    Args:\n",
        "        predictions (torch.tensor): tensor of shape of (B,C)\n",
        "        labels (torch.tensor): tensor of shape of (B,1)\n",
        "    Returns:\n",
        "        torch.tensor: a tensor of shape of (1,)\n",
        "    \"\"\"\n",
        "    ### TODO: Fill out this function\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tJxocVAKAiV"
      },
      "source": [
        "### 1.3 Network (2.5 + 7.5 pts)\n",
        "Complete the code for the simple feed-forward network shown below. \n",
        "\n",
        "Network parameters will be stored in a dictionary called `params`. weights and biases keys appear in the format `W#` and `b#` where `#` indicates the layer number. For example, the weights and biases of the first layer are `W1` and `b1`. Weights and biases are initialized inside `init_weights` function.\n",
        "\n",
        "**Notes:** \n",
        "1. Set `requires_grad=True` when initializing weights and biases to have [pytorch automatic differentiation engine](https://pytorch.org/docs/stable/autograd.html) calculate the gradients.\n",
        "2. Assign network parameters and inputs on the same `device`.\n",
        "3. Initialize weights and biases with samples from normal distribution with mean 0 and variance 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_BV_J1NKAiW"
      },
      "source": [
        "params = {}\n",
        "\n",
        "class my_nn:\n",
        "    def __init__(self,layers_dim,layers_activation=None,device='cpu'):\n",
        "        \"\"\" Initialize network\n",
        "        Args:\n",
        "            layers_dims (List of ints): list of Size of each layer of the network\n",
        "                                        [inputs,layer1,...,outputs]\n",
        "            layers_activation (List of strings): list of activation function for each hidden layer\n",
        "                                        of the network[layer1,...,outputs]\n",
        "            device (str): a device that will be used for computation\n",
        "                Default: 'cpu'\n",
        "            \n",
        "        \"\"\"\n",
        "        self.layers_activation = layers_activation\n",
        "        self.params = {}\n",
        "        self.num_layers = len(layers_dim)-1\n",
        "        self.layers_dim = layers_dim\n",
        "        self.device = device\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        \"\"\" Initialize weights and biases of network based on layers dimension.\n",
        "            Store weights and biases in self.params.\n",
        "            weights and biases key should be of format \"W#\" and \"b#\" where # is the layer number.\n",
        "            Example: for layer 1, weight and bias key is \"W1\" and \"b1\"\n",
        "        Args:\n",
        "            None\n",
        "        \n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        ### TODO: Initialize weights and bias of network\n",
        "        ### TODO: Store weights and biases in self.params\n",
        "        ### HINT: Remember to set require_grad to True\n",
        "        ### HINT: Remember to put tensors of target device\n",
        "        pass\n",
        "\n",
        "    def forward(self,x):\n",
        "        \"\"\" Perform forward pass\n",
        "        Args:\n",
        "            x (torch.tensor): tensor of shape of (B, C, H, W)\n",
        "        \n",
        "        Return:\n",
        "            torch.tensor: tensor of shape of (B, N_classes)\n",
        "        \"\"\"\n",
        "        ### TODO: Fill out this function\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzH7h-aDKAiY"
      },
      "source": [
        "### 1.4 Training the network (12+12+6 pts)\n",
        "Complete and run the following cells to train the network. You can use the predefined network hyper parameters or try your own."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XCEZfcKKAia"
      },
      "source": [
        "def Train(model,optimizer,dataloader,device):\n",
        "    \"\"\" performs training on train set\n",
        "    Args:\n",
        "        model (my_nn instance): model to be trained\n",
        "        optimizer (torch.optim instance)\n",
        "        dataloader (torch.utils.data.DataLoader instance): dataloader for train set\n",
        "        device (str): computation device ['cpu','cuda',...]\n",
        "    Returns:\n",
        "        list of floats: mini_batch loss sampled every 20 steps for visualization purposes\n",
        "        list of floats: mini_batch accuracy sampled every 20 steps for visualization purposes\n",
        "    \"\"\"\n",
        "    loss_tracker = []\n",
        "    accuracy_tracker = []\n",
        "    for i,(data,label) in enumerate(dataloader):\n",
        "        ### TODO: Put data and label on target device\n",
        "\n",
        "        ### TODO: Set gradients to zero\n",
        "\n",
        "        ### TODO: Pass data to the model\n",
        "\n",
        "        ### TODO: Calculate the loss of predicted labels vs ground truth labels\n",
        "\n",
        "        ### TODO: Calculate gradients and update weights and biases\n",
        "\n",
        "        if i % 20:\n",
        "            with torch.no_grad():\n",
        "                loss_tracker.append(loss.item())\n",
        "                ### TODO: calculate accuracy of mini_batch\n",
        "                accuracy = None\n",
        "                accuracy_tracker.append(accuracy/data.size(0))\n",
        "            \n",
        "    return loss_tracker, accuracy_tracker\n",
        "\n",
        "def Test(model,dataloader,device):\n",
        "    \"\"\" performs training on train set\n",
        "    Args:\n",
        "        model (my_nn instance): model to be trained\n",
        "        dataloader (torch.utils.data.DataLoader instance)\n",
        "        device (str): computation device ['cpu','cuda',...]\n",
        "    Returns:\n",
        "        floats: test set loss for visualization purposes\n",
        "        floats: test set accuracy for visualization purposes\n",
        "    \"\"\"\n",
        "    loss_tracker = []\n",
        "    accuracy_tracker = []\n",
        "    for i,(data,label) in enumerate(dataloader):\n",
        "        ### TODO: Put data and label on target device\n",
        "\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            ### TODO: Pass data to the model\n",
        "\n",
        "            ### TODO: Calculate the loss of predicted labels vs ground truth labels\n",
        "           \n",
        "            ### TODO: calculate accuracy of mini_batch\n",
        "            accuracy = None\n",
        "            \n",
        "        loss_tracker.append(loss.item())\n",
        "        accuracy_tracker.append(accuracy/data.size(0))\n",
        "        \n",
        "    return sum(loss_tracker)/len(loss_tracker), sum(accuracy_tracker)/len(accuracy_tracker)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRgQgscVKAib"
      },
      "source": [
        "# Training hyper parameters\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "layers_dim = [28*28,512,512,10]\n",
        "\n",
        "### TODO: Set target device for computations\n",
        "device = None\n",
        "print(f'device: {device}')\n",
        "\n",
        "\n",
        "### TODO: Initialize model using layers_dim\n",
        "model = None\n",
        "### TODO: Initialize Adam optimizer\n",
        "optimizer = None\n",
        "\n",
        "train_loss_tracker = []\n",
        "train_accuracy_tracker = []\n",
        "\n",
        "test_loss_tracker = []\n",
        "test_accuracy_tracker = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f'Epoch: {epoch}')\n",
        "    train_loss,train_accuracy = Train(model,optimizer,kmnist_train_loader,device)\n",
        "    test_loss , test_accuracy = Test(model,kmnist_test_loader,device)\n",
        "    train_loss_tracker.extend(train_loss)\n",
        "    train_accuracy_tracker.extend(train_accuracy)\n",
        "    test_loss_tracker.append(test_loss)\n",
        "    test_accuracy_tracker.append(test_accuracy)\n",
        "    print('\\t training loss/accuracy: {0:.2f}/{1:.2f}'.format(sum(train_loss)/len(train_loss), sum(train_accuracy)/len((train_accuracy))))\n",
        "    print('\\t testing loss/accuracy: {0:.2f}/{1:.2f}'.format(test_loss, test_accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ac_LFfwJKAib",
        "scrolled": true
      },
      "source": [
        "### TODO: visualize train_loss and train_accuracy\n",
        "### TODO: visualize test_loss and test_accuracy\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIo6qu1jKAic"
      },
      "source": [
        "## 2 Convolutional Neural Network (CNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZayT7BO8QNV2"
      },
      "source": [
        "Implement a CNN and train your network. Using GPU will dramatically increase the training speed. If you are planning on using [Google Colab](https://colab.research.google.com/), one way to load the dataset is to load it from your google drive. Run the cell below to mount your google drive storage. If you are training on your local machine, comment out the following two lines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wn7FtKW4Ln1b"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ce6IrzbBKAic"
      },
      "source": [
        "In this section, we will use the [Stanford Dogs Dataset](http://vision.stanford.edu/aditya86/ImageNetDogs/). You only need download [images](http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar) (Extract and upload this folder to your google drive if you are planning to use google colab). \n",
        "\n",
        "Run the cells below to load and visualize this dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXSRH8w1cIfZ"
      },
      "source": [
        "# load dataset from path\n",
        "# set path to images location on your local machine or google drive\n",
        "#path = 'drive/MyDrive/images/Images'  # Google drive\n",
        "path = './images/Images'               #local machine\n",
        "dataset = ImageFolder(path)\n",
        "print(f'number of images: {len(dataset)}')\n",
        "print(f'number of classes: {len(dataset.classes)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPe_cqDPcIfa"
      },
      "source": [
        "# Create train and test splits of original dataset\n",
        "test_pct = 0.3\n",
        "test_size = int(len(dataset)*test_pct)\n",
        "train_size = len(dataset) - test_size\n",
        "train_ds, test_ds = random_split(dataset, [train_size, test_size])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6WlRHFxOw73"
      },
      "source": [
        "# In order to apply transformations, we use a custom dataset\n",
        "# see https://pytorch.org/docs/stable/data.html#iterable-style-datasets\n",
        "class DogBreedDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, ds, transform=None):\n",
        "        self.ds = ds\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.ds)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img, label = self.ds[idx]\n",
        "        if self.transform:\n",
        "            img = self.transform(img)  \n",
        "            return img, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cmm9TWo_cIfb"
      },
      "source": [
        "batch_size =64\n",
        "\n",
        "#train set transforms\n",
        "train_transform = transforms.Compose([\n",
        "   transforms.Resize((240, 240)),\n",
        "    transforms.ToTensor()    \n",
        "])\n",
        "\n",
        "# test set transforms\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((240,240)), \n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Initialize train and test sets\n",
        "train_dataset = DogBreedDataset(train_ds, train_transform)\n",
        "test_dataset = DogBreedDataset(test_ds, test_transform)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_dl = DataLoader(train_dataset, batch_size, shuffle=True)\n",
        "test_dl = DataLoader(test_dataset, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5N0-ApkcIfc"
      },
      "source": [
        "def show_batch(dl):\n",
        "    for img, lb in dl:\n",
        "        fig, ax = plt.subplots(figsize=(16, 8))\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "        ax.imshow(make_grid(img.cpu(), nrow=16).permute(1,2,0))\n",
        "        break\n",
        "show_batch(train_dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "penyN1C-KAid"
      },
      "source": [
        "### 2.1 Custom CNN (10* + 2.5 + 12.5 pts)\n",
        "Create your own `conv_net`. Apply `ReLU` activation function after each convolution layer.\n",
        "\n",
        "**Extra credit for undergraduates/Compulsory for graduates**: Implement a `my_conv2d` class to replace `torch.nn.Conv2d`.\n",
        "\n",
        "**Extra credit for all**: Implement [Xavier initialization](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf?hc_location=ufi]) to initialize network weights. Do not use `torch.nn.init` module for this task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVjaIvqhwoQf"
      },
      "source": [
        "class my_conv2d:\n",
        "    ### EXTRA CREDIT FOR UNDERGRADUATES - ### TODO: Compulsory for graduates\n",
        "    ### Complete this class to have the perform the convolution similar to torch.nn.Conv2d \n",
        "    def __init__(self,):\n",
        "        pass\n",
        "    \n",
        "    def forward(self,x):\n",
        "        pass\n",
        "\n",
        "    \n",
        "\n",
        "class conv_net(nn.Module):\n",
        "    def __init__(self):\n",
        "        \"\"\" Initialize conv_net\n",
        "        Args:\n",
        "            None\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        super(conv_net,self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 100, kernel_size = 11, stride = 3)\n",
        "        self.max_pool1 = nn.MaxPool2d(kernel_size = 3, stride = 2)\n",
        "        self.conv2 = nn.Conv2d(in_channels = 100, out_channels = 512, kernel_size = 3, stride = 1)\n",
        "        self.conv3 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 2)\n",
        "        self.max_pool2 = nn.MaxPool2d(kernel_size = 3, stride = 2)\n",
        "        self.conv4 = nn.Conv2d(in_channels = 512, out_channels = 256, kernel_size = 3, stride = 1)\n",
        "        self.conv5 = nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, stride = 1)\n",
        "        self.max_pool3 = nn.MaxPool2d(kernel_size = 3, stride = 1)\n",
        "        ### TODO: calculate number of in_features for this layer\n",
        "        self.linear = nn.Linear(in_features = None , out_features = 120)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        ### EXTRA CREDIT FOR ALL: initialize network weights based on Xavier initialization\n",
        "        pass\n",
        "    \n",
        "    def forward(self,x):\n",
        "        \"\"\" Perform forward pass\n",
        "        Args:\n",
        "            x (torch.tensor): tensor of images of shape  (B, C, H, W)\n",
        "        Returns:\n",
        "            torch.tensor: tesnor of output of shape (B, N_classes)\n",
        "        \"\"\"\n",
        "        ### TODO: fill out this function\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bztsm81kKAid"
      },
      "source": [
        "### 2.2 Training the network (3.5 + 3.5 pts)\n",
        "Re-use the previously implemented Train and Test functions. Complete the missing parts below and run cells to train `conv_net` and visualize the training statistics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opliQtf0xTAt"
      },
      "source": [
        "# Training hyper parameters\n",
        "epochs = 20\n",
        "learning_rate = 0.001\n",
        "\n",
        "### TODO: Set target device for computations\n",
        "device = None\n",
        "print(f'device: {device}')\n",
        "\n",
        "\n",
        "### TODO: Initialize conv_net\n",
        "model = None\n",
        "### TODO: Put model parameters on target device\n",
        "\n",
        "### TODO: Initialize Adam optimizer\n",
        "optimizer = None\n",
        "\n",
        "train_loss_tracker = []\n",
        "train_accuracy_tracker = []\n",
        "\n",
        "test_loss_tracker = []\n",
        "test_accuracy_tracker = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss,train_accuracy = Train(model,optimizer,train_dl,device)\n",
        "    test_loss , test_accuracy = Test(model,test_dl,device)\n",
        "    train_loss_tracker.extend(train_loss)\n",
        "    train_accuracy_tracker.extend(train_accuracy)\n",
        "    test_loss_tracker.append(test_loss)\n",
        "    test_accuracy_tracker.append(test_accuracy)\n",
        "    print(f'epoch: {epoch}')\n",
        "    print('\\t training loss/accuracy: {0:.2f}/{1:.2f}'.format(sum(train_loss)/len(train_loss), sum(train_accuracy)/len((train_accuracy))))\n",
        "    print('\\t testing loss/accuracy: {0:.2f}/{1:.2f}'.format(test_loss, test_accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1O7BBD35KAie"
      },
      "source": [
        "### TODO: visualize train_loss and train_accuracy\n",
        "### TODO: visualize test_loss and test_accuracy\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-KcFEv1KAie"
      },
      "source": [
        "### 2.3 Ablation study of filters (10 pts)\n",
        "In practice, for many computer vision tasks, training the network from scratch is not recommended since it is time consuming and requires a vase amount of labeled data for training. Instead, one can use networks trained for image classification on benchmark datasets such as ImageNet to initialize a new network. In particular, the initial layers of the pre-trained networks extract general features and can therefore be used to initialize the initial layers of a new network.\n",
        "\n",
        "In this part,you will visualize some of the filters from the first layer of [AlexNet](https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html) and the results of their application on a sample image from the Stanford dogs dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07usBkfaXi-B"
      },
      "source": [
        "Run the cell below to load a pretrained Alexnet using [PyTorch Hub](https://pytorch.org/docs/stable/hub.html)'s [`torch.hub.load()`](https://pytorch.org/docs/stable/hub.html#torch.hub.load) method. The model is switched to `eval()` as we are using it only for inference. Running this cell will display the architecture of the `Alexnet`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTzV5k2aKAie",
        "scrolled": true
      },
      "source": [
        "# load the alexnet model using pytorch hub from:\n",
        "# https://github.com/pytorch/vision/blob/winbuild/v0.6.0/torchvision/models/alexnet.py\n",
        "model = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=True)\n",
        "\n",
        "# switch the model to \"eval\" mode\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaAcMWdvXqI9"
      },
      "source": [
        "Since we are using a pretrained model, our data distribution should match the distribution of the training data. Here, we normalize the input similar to [original training pipeline](https://github.com/pytorch/examples/blob/97304e232807082c2e7b54c597615dc0ad8f6173/imagenet/main.py#L197-L198).\n",
        "\n",
        "Run the cell below to load and normalize a sample image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0o5Sb_8uXubk"
      },
      "source": [
        "data,_ = next(iter(train_dl))\n",
        "sample_image = data[0]\n",
        "\n",
        "# the mean and standard deviations of ImageNet dataset \n",
        "# that were used for preprocessing AlexNet training data\n",
        "mean = np.array([0.485, 0.456, 0.406])\n",
        "std = np.array([0.229, 0.224, 0.225])\n",
        "\n",
        "### TODO: normalize sample_image using the mean and standard deviations of ImageNet dataset \n",
        "sample_image_processed = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7ro8OniX19Z"
      },
      "source": [
        "### TODO: visualize the sample image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OgtYH0oKAif"
      },
      "source": [
        "Visualize a randomly selected subset of 20 of these first layer filters as well as the respective output of convolving each kernel with a sample image. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kM5QJg9KAif"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# first layer of Alexnet\n",
        "first_layer = model.features[0]\n",
        "\n",
        "### TODO: get weights of first layer kernels of the model\n",
        "\n",
        "### TODO: pass sample image to the first layer\n",
        "\n",
        "### TODO: randomly select 20 filters out of 64\n",
        "\n",
        "### TODO: show selected kernel and their convolution output on sample image.\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}